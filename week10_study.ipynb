{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python372jvsc74a57bd0b32d515efec0826b323c15074e20e692f6cbcd1b1b493737311455e40016c713",
   "display_name": "Python 3.7.2 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "b32d515efec0826b323c15074e20e692f6cbcd1b1b493737311455e40016c713"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.datasets import load_files\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train = load_files(\"./aclImdb/train\")\n",
    "text_train, y_train = reviews_train.data, reviews_train.target\n",
    "\n",
    "reviews_test = load_files(\"./aclImdb/test\")\n",
    "text_test, y_test = reviews_test.data, reviews_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = [doc.replace(b\"<br />\", b\" \") for doc in text_train]\n",
    "text_test = [doc.replace(b\"<br />\", b\" \") for doc in text_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer().fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "X_test = vect.transform(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB(alpha=15)\n",
    "nb.fit(X_train, y_train)\n",
    "pre = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8\n"
     ]
    }
   ],
   "source": [
    "ac_score = metrics.accuracy_score(y_test, pre)\n",
    "print(ac_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.datasets import load_files\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer().fit(text_train)\n",
    "X_train = vect.transform(text_train)\n",
    "X_test = vect.transform(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB(alpha=0.5)\n",
    "nb.fit(X_train, y_train)\n",
    "pre = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.807\n"
     ]
    }
   ],
   "source": [
    "ac_score = metrics.accuracy_score(y_test, pre)\n",
    "print(ac_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import konlpy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"./sample_data/ratings_train.txt\", delimiter = \"\\t\", keep_default_na = False)\n",
    "df_test = pd.read_csv(\"./sample_data/ratings_test.txt\", delimiter = \"\\t\", keep_default_na = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "         id                                           document  label\n0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n        id                                           document  label\n0  6270596                                                굳 ㅋ      1\n1  9274899                               GDNTOPCLASSINTHECLUB      0\n2  8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n3  6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n4  6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0\n"
     ]
    }
   ],
   "source": [
    "print(df_train.head(5))\n",
    "print(df_test.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "150000 [75173 74827]\n50000 [24827 25173]\n"
     ]
    }
   ],
   "source": [
    "text_train = df_train['document']\n",
    "y_train = df_train['label']\n",
    "\n",
    "text_test = df_test['document']\n",
    "y_test = df_test['label']\n",
    "\n",
    "print(len(text_train), np.bincount(y_train))\n",
    "print(len(text_test), np.bincount(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\ibo70\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\jpype\\_core.py:210: UserWarning: \n-------------------------------------------------------------------------------\nDeprecated: convertStrings was not specified when starting the JVM. The default\nbehavior in JPype will be False starting in JPype 0.8. The recommended setting\nfor new code is convertStrings=False.  The legacy value of True was assumed for\nthis session. If you are a user of an application that reported this warning,\nplease file a ticket with the developer.\n-------------------------------------------------------------------------------\n\n  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "twitter = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['단독', '입찰', '보다', '복수', '입찰', '의', '경우']\n['항공기', '체계', '종합', '개발', '경험', '회사']\n['날카로운 분석', '날카로운 분석과 신뢰감', '날카로운 분석과 신뢰감 있는 진행', '분석', '신뢰', '진행']\n[('이', 'Determiner'), ('것', 'Noun'), ('도', 'Josa'), ('되나욬', 'Noun'), ('ㅋㅋ', 'KoreanParticle'), ('?', 'Punctuation')]\n[('이', 'Determiner'), ('것', 'Noun'), ('도', 'Josa'), ('되나요', 'Verb'), ('ㅋㅋ', 'KoreanParticle'), ('?', 'Punctuation')]\n[('이', 'Determiner'), ('것', 'Noun'), ('도', 'Josa'), ('되다', 'Verb'), ('ㅋㅋ', 'KoreanParticle'), ('?', 'Punctuation')]\n['이/Determiner', '것/Noun', '도/Josa', '되다/Verb', 'ㅋㅋ/KoreanParticle', '?/Punctuation']\n"
     ]
    }
   ],
   "source": [
    "print(twitter.morphs(u\"단독입찰보다 복수입찰의 경우\"))\n",
    "print(twitter.nouns(\"유일하게 항공기 체계 종합개발 경험을 갖고 있는 회사는\"))\n",
    "print(twitter.phrases(\"날카로운 분석과 신뢰감 있는 진행으로\"))\n",
    "\n",
    "print(twitter.pos(\"이것도 되나욬ㅋㅋ?\"))\n",
    "print(twitter.pos(\"이것도 되나욬ㅋㅋ?\", norm=True))\n",
    "print(twitter.pos(\"이것도 되나욬ㅋㅋ?\", norm=True, stem=True))\n",
    "print(twitter.pos(\"이것도 되나욬ㅋㅋ?\", norm=True, stem=True, join=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okt morphs를 사용한 단순한 tokenizer 함수\n",
    "def twitter_tokenizer(text):\n",
    "    return twitter.morphs(text)\n",
    "\n",
    "def twitter_tokenizer_filter(text):\n",
    "    malist = twitter.pos(text, norm=True, stem=True)\n",
    "    r = []\n",
    "    for word in malist:\n",
    "        if not word[1] in [\"Josa\", \"Eomi\", \"Punctuation\", \"KoreanParticle\"]:\n",
    "            r.append(word[0])\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['유일하게', '항공기', '체계', '종합', '개발', '경험', '을', '갖고', '있는', '회사', '는']\n"
     ]
    }
   ],
   "source": [
    "print(twitter_tokenizer(\"유일하게 항공기 체계 종합개발 경험을 갖고 있는 회사는\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['유일하다', '항공기', '체계', '종합', '개발', '경험', '갖다', '있다', '회사']\n"
     ]
    }
   ],
   "source": [
    "print(twitter_tokenizer_filter(\"유일하게 항공기 체계 종합개발 경험을 갖고 있는 회사는\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import konlpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "twitter = Okt()\n",
    "\n",
    "def twitter_tokenizer_filter(text):\n",
    "    malist = twitter.pos(text, norm=True, stem=True)\n",
    "    r = []\n",
    "    for word in malist:\n",
    "        if not word[1] in [\"Josa\", \"Eomi\", \"Punctuation\", \"KoreanParticle\"]:\n",
    "            r.append(word[0])\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"./sample_data/ratings_train.txt\", delimiter=\"\\t\", keep_default_na = False)\n",
    "df_test = pd.read_csv(\"./sample_data/ratings_test.txt\", delimiter=\"\\t\", keep_default_na = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = df_train['document']\n",
    "y_train = df_train['label']\n",
    "\n",
    "text_test = df_test['document']\n",
    "y_test = df_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(tokenizer = twitter_tokenizer_filter).fit(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vect.transform(text_train)\n",
    "clf_mult = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vect.transform(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = clf_mult.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8402\n"
     ]
    }
   ],
   "source": [
    "ac_score = metrics.accuracy_score(y_test, pre)\n",
    "print(ac_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text = open(\"./sample_data/speech.txt\", encoding = \"ISO8859\").read()\n",
    "\n",
    "wordcloud = WordCloud().generate(text)\n",
    "\n",
    "print(type(wordcloud))\n",
    "\n",
    "print(type(wordcloud.word_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wordcloud.word_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(max_fontsize = 70).generate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(wordcloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(wordcloud, interpolation = \"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 예제\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
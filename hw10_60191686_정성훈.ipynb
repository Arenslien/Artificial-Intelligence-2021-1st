{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python372jvsc74a57bd0b32d515efec0826b323c15074e20e692f6cbcd1b1b493737311455e40016c713",
   "display_name": "Python 3.7.2 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "b32d515efec0826b323c15074e20e692f6cbcd1b1b493737311455e40016c713"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인공지능 Homework 10\n",
    "# 이름: 정성훈\n",
    "# 학번: 60191686\n",
    "\n",
    "# 1. 강의시간에 활용했던 한글 영화평 데이터(ratings_train.txt, ratings_test.txt)를 사용하여 다음에 해당하는 코드를 작성하시오. 아래 모든 문항에 대한 설명과 충분한 증빙자료(코드, 스크린 샷, 주석 등)가 보고서에 포함되어야 합니다.\n",
    "\n",
    "# 라이브러리 사용\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_files\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - a)\n",
    "\n",
    "# 영화평 데이터 파일 loading & train data와 test data로 분리\n",
    "train_data = pd.read_csv(\"./sample_data/ratings_train.txt\", delimiter=\"\\t\", keep_default_na=False)\n",
    "valid_data = pd.read_csv(\"./sample_data/ratings_test.txt\", delimiter=\"\\t\", keep_default_na=False)\n",
    "\n",
    "# 데이터와 Label로 분리\n",
    "train_x, train_y = train_data['document'], train_data['label']\n",
    "valid_x, valid_y = valid_data['document'], valid_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - b)\n",
    "# 해당 영화평 데이터 파일에는 <br /> 태그가 없으므로 따로 제거하지 않았습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\n['흠', '포스터', '보고', '초딩', '영화', '줄', '오버', '연기', '가볍다', '않다']\n"
     ]
    }
   ],
   "source": [
    "# 1 - c)\n",
    "\n",
    "\n",
    "# Okt 사용\n",
    "twitter = Okt()\n",
    "\n",
    "# 토크나이저 함수 정의\n",
    "def tokenizer_korean(text):\n",
    "    morphed_list = twitter.pos(text, norm=True, stem=True)\n",
    "    result = []\n",
    "    for word in morphed_list:\n",
    "        if not word[1] in [\"Josa\", \"Eomi\", \"Punctuation\", \"KoreanParticle\"]:\n",
    "            result.append(word[0])\n",
    "    return result\n",
    "\n",
    "# 테스트 데이터 토크나이저 적용 전과 후 비교\n",
    "print(train_x[1])\n",
    "print(tokenizer_korean(train_x[1]))\n",
    "\n",
    "# 학습데이터에 대한 BOW 생성 & 불용어 제거\n",
    "vect = CountVectorizer(tokenizer = tokenizer_korean, stop_words = \"english\").fit(train_x)\n",
    "\n",
    "# train & test 입력 데이터들을 변환\n",
    "X_train = vect.transform(train_x)\n",
    "X_test = vect.transform(valid_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy = 0.83\n"
     ]
    }
   ],
   "source": [
    "# 1 - d)\n",
    "\n",
    "# 데이터 학습시키기 \n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(X_train, train_y)\n",
    "\n",
    "# 데이터 예측하기\n",
    "predict = clf.predict(X_test)\n",
    "\n",
    "# 결과 테스트하기\n",
    "ac_score = metrics.accuracy_score(predict, valid_y)\n",
    "print(\"Accuracy =\", round(ac_score, 2))\n",
    "\n",
    "# Accuracy = 0.83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\ibo70\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "Accuracy = 0.81\n"
     ]
    }
   ],
   "source": [
    "# 1 - e)\n",
    "\n",
    "# 데이터 학습시키기 \n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, train_y)\n",
    "\n",
    "# 데이터 예측하기\n",
    "predict = clf.predict(X_test)\n",
    "\n",
    "# 결과 테스트하기\n",
    "ac_score = metrics.accuracy_score(predict, valid_y)\n",
    "print(\"Accuracy =\", round(ac_score, 2))\n",
    "\n",
    "# Accuracy = 0.81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy = 0.84\n"
     ]
    }
   ],
   "source": [
    "# 1 - e)\n",
    "\n",
    "# 데이터 학습시키기 \n",
    "clf = RandomForestClassifier(n_estimators=500)\n",
    "clf.fit(X_train, train_y)\n",
    "\n",
    "# 데이터 예측하기\n",
    "predict = clf.predict(X_test)\n",
    "\n",
    "# 결과 테스트하기\n",
    "ac_score = metrics.accuracy_score(predict, valid_y)\n",
    "print(\"Accuracy =\", round(ac_score, 2))\n",
    "\n",
    "# Accuracy = 0.84"
   ]
  }
 ]
}